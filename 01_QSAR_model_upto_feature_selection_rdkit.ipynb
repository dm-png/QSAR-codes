{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e0731f6-9643-4922-b464-c054596f6275",
   "metadata": {},
   "source": [
    "## Data curation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3cf0d-fbf0-4f69-b4d1-77d157334995",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0acf63-e967-41d9-a8ac-2f7ebb6e134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from rdkit.Chem import Descriptors\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1a506-0d61-4b3a-86e0-af7527eb5564",
   "metadata": {},
   "source": [
    "### 2. Load and review the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0886ae90-2ae9-4702-b07e-49db4c540968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2279602-3ceb-4327-a6fa-47a62daed2da",
   "metadata": {},
   "source": [
    "### 3. Remove duplicates based on smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8771e2a4-59c5-4943-ad12-e77c82c46639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df = df.drop_duplicates(subset=['Smiles'], keep='first')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18c2ebb-63a6-4880-8f82-b581680f9690",
   "metadata": {},
   "source": [
    "### 4. Handling of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6757613-e1ca-4c38-9076-8335bffa9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing pChEMBL Value\n",
    "df = df.dropna(subset=['pChEMBL Value'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94340d3d-0706-49d7-acfb-a2aadc9783fc",
   "metadata": {},
   "source": [
    "### 5. Outlier analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe4309-f2c6-4e79-8447-1797e78820b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR for pChEMBL Value\n",
    "Q1 = df['pChEMBL Value'].quantile(0.25)\n",
    "Q3 = df['pChEMBL Value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define upper and lower bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the DataFrame to remove outliers\n",
    "df = df[(df['pChEMBL Value'] >= lower_bound) & (df['pChEMBL Value'] <= upper_bound)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f8911-059f-4e0a-9cd3-6babf4c4bddd",
   "metadata": {},
   "source": [
    "### 6. Retain specific columns and rename them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ecb74-6576-4bde-ba95-e85f45d591e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the specified columns\n",
    "df = df[['Molecule ChEMBL ID', 'Smiles', 'pChEMBL Value']]\n",
    "\n",
    "# Rename the columns\n",
    "df.columns = ['Molecule', 'SMILES', 'pEC50']\n",
    "\n",
    "# Save the cleaned dataset with the desired columns and new names\n",
    "cleaned_file_path = '/rdkit/cleaned_data.csv'  # specify your desired path\n",
    "df.to_csv(cleaned_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709a88d-6589-4917-b118-fd7bdc266cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d2ea5-9440-4ad4-887f-69e4f9082f6e",
   "metadata": {},
   "source": [
    "### 7. Distribution of pIC50 valuesÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef26f9f7-5a7a-4e79-9368-6006556d7c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style of seaborn\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Create a line plot for the probability distribution of pIC50 values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(df['pEC50'], fill=True, color='blue', alpha=0.2)  # Kernel Density Estimate\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Probability Distribution of pEC50 Values', fontsize=16)\n",
    "plt.xlabel('pEC50', fontsize=14)\n",
    "plt.ylabel('Density', fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a51de80-461b-4b58-aa22-36f12d44fd6b",
   "metadata": {},
   "source": [
    "### 8. Extracting the SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff70d7-2b72-4aaa-aa6d-4d6a0d7442d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =  df['SMILES']\n",
    "df2.to_csv('molecule.smi', index=False, header=False)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f81cde-bee0-45e6-91d1-8301d939f07c",
   "metadata": {},
   "source": [
    "### 9. Calculating PaDEL descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35eeab8-a52e-434d-a03f-3c4a10338dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = df['SMILES'].values\n",
    "sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd53b1a-1c5a-474c-9081-8818ee3f4850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_descriptors(smiles_list):\n",
    "    descriptors_list = []\n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            # Calculate all molecular descriptors\n",
    "            descriptors = Descriptors.CalcMolDescriptors(mol)\n",
    "            descriptors_list.append(descriptors)\n",
    "        else:\n",
    "            # Append NaNs for missing molecules\n",
    "            descriptors_list.append([None] * len(Descriptors._descList))\n",
    "    return pd.DataFrame(descriptors_list, columns=[desc[0] for desc in Descriptors._descList])\n",
    "\n",
    "descriptors_df = calculate_descriptors(sm)\n",
    "\n",
    "\n",
    "descriptors_df.to_csv(\"/rdkit/descriptors.csv\", index=False)\n",
    "# Concatenate the original DataFrame with the descriptors DataFrame\n",
    "#result_df = pd.concat([df.reset_index(drop=True), descriptors_df], axis=1)\n",
    "\n",
    "# Display the result DataFrame\n",
    "#print(result_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0631c3-4daf-483b-94b9-86808b305826",
   "metadata": {},
   "source": [
    "### 10. Concatnetae descriptor data with molecules and pIC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c810d7-b883-4501-94e4-5fc6e110d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original DataFrame (df) with 'Molecule', 'SMILES', and 'pIC50' columns\n",
    "# Assuming df is already available in your environment\n",
    "\n",
    "# Load descriptors.csv, skip the first column\n",
    "descriptors_df = pd.read_csv('CHEMBL941720/rdkit/descriptors.csv').iloc[:, 1:]\n",
    "\n",
    "# Concatenate the original columns (Molecule, SMILES, pIC50) with descriptors\n",
    "# First, reset the index of `df` and `descriptors_df` to ensure they align correctly\n",
    "result_df = pd.concat([df[['Molecule', 'SMILES']].reset_index(drop=True), descriptors_df, df[['pEC50']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Save the final DataFrame to a new CSV file\n",
    "result_df.to_csv('/rdkit/final_descriptors.csv', index=False)\n",
    "print(\"The new file 'final_descriptors.csv' has been created with the required columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4cb95a-0808-44f5-95c0-e5b8cb8f83f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885d262-9d40-452a-957b-93217440f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d9f2c-db7e-4d88-81ed-f3f9f2a6c148",
   "metadata": {},
   "source": [
    "### 11. Descriptor reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b8946d-5a91-4840-85cd-2e04eeb71b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/rdkit/final_descriptors.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a00ea3-b410-4d59-abc9-e89e0d8a616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with any missing values\n",
    "data = data.dropna(axis=1)\n",
    "\n",
    "# Step 1: Remove virtually constant columns (>95% same values)\n",
    "# Calculate the percentage of unique values in each column\n",
    "constant_columns = [col for col in data.columns[1:-1] if data[col].value_counts(normalize=True).values[0] > 0.95]\n",
    "data = data.drop(columns=constant_columns)\n",
    "\n",
    "# Step 2: Remove highly correlated columns (|r| > 0.90)\n",
    "# Compute the correlation matrix for the remaining descriptors\n",
    "corr_matrix = data.iloc[:, 2:-1].corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find index of columns with correlation greater than 0.90\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.90)]\n",
    "data = data.drop(columns=to_drop)\n",
    "\n",
    "# Display the results\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7cc7a8-16c3-42c0-87c0-8bbea7b6660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e2df2-4170-4fee-9f9b-1276cb728460",
   "metadata": {},
   "source": [
    "### 12. Feature Selection via RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4977016a-91e7-4ba9-b5f3-7e9b294f1f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Separate the predictors and target variable\n",
    "X = data.iloc[:, 2:-1]  # Descriptors\n",
    "y = data.iloc[:, -1]     # pIC50\n",
    "\n",
    "# Define the model and RFE\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=8)  # Adjust to select your desired number of top features\n",
    "\n",
    "# Fit RFE to data\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ebbe91-1f74-4d91-851e-3083ae47def7",
   "metadata": {},
   "source": [
    "### 13. Feature selection via stepwise regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e2d09-8694-4cc9-a7e4-25375764fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# Load data\n",
    "\n",
    "X = data.iloc[:, 2:-1]  # Descriptors (assuming the first column is compound key)\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "def stepwise_selection(X, y, threshold_in=0.05, threshold_out=0.05, max_features=8):\n",
    "    included = []\n",
    "    while len(included) < max_features:\n",
    "        changed = False\n",
    "\n",
    "        # Forward step: Try adding features\n",
    "        excluded = list(set(X.columns) - set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "\n",
    "        for col in excluded:\n",
    "            model = sm.OLS(y, add_constant(X[included + [col]])).fit()\n",
    "            new_pval[col] = model.pvalues[col]\n",
    "\n",
    "        # Select the best feature with p-value below the threshold_in\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed = True\n",
    "\n",
    "        # Check if we've reached the max_features limit\n",
    "        if len(included) >= max_features:\n",
    "            break\n",
    "\n",
    "        # Backward step: Try removing features with p-value above the threshold_out\n",
    "        model = sm.OLS(y, add_constant(X[included])).fit()\n",
    "        pvalues = model.pvalues.iloc[1:]  # Skip intercept\n",
    "        worst_pval = pvalues.max()\n",
    "\n",
    "        if worst_pval > threshold_out:\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            changed = True\n",
    "\n",
    "        # Break if no changes occurred (i.e., stable subset reached)\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    # Final model to print the selected features' details\n",
    "    final_model = sm.OLS(y, add_constant(X[included])).fit()\n",
    "    print(final_model.summary())\n",
    "    return included\n",
    "\n",
    "# Run stepwise selection with a specific maximum number of features\n",
    "selected_features = stepwise_selection(X, y, max_features=8)\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e201d7-6f66-4ec0-aa88-1fcfbdd8861b",
   "metadata": {},
   "source": [
    "### 14. Building the multiple linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f659bb3b-549d-44e3-8c6c-3452c907ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "# Separate predictors and target variable based on selected descriptors\n",
    "X = data[['qed', 'FpDensityMorgan1', 'FpDensityMorgan2', 'BCUT2D_MWLOW',\n",
    "       'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'BalabanJ',\n",
    "       'NumAliphaticHeterocycles']]\n",
    "y = data[\"pEC50\"]\n",
    "\n",
    "# Bin y into bins\n",
    "y_binned = pd.qcut(y, q=5, duplicates='drop') \n",
    "\n",
    "# Split data into training and test sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y_binned)\n",
    "\n",
    "# Initialize and fit the MLR model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e3109-ddf4-46c7-b26a-82665d575546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean performance:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5628e0-aad4-4823-9251-adc716fb3b05",
   "metadata": {},
   "source": [
    "### 15. Save the dataset for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce0f4d-4110-45b5-ad36-2a1f99571a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The selected feature columns\n",
    "selected_features = ['PEOE_VSA12', 'fr_morpholine']\n",
    "\n",
    "# Ensure that 'Compound Key' and 'pIC50' are part of the data\n",
    "# Select the relevant columns from your dataset\n",
    "selected_columns = ['Molecule'] + selected_features + ['pIC50']\n",
    "\n",
    "# Create a new DataFrame with the selected columns\n",
    "selected_data = data[selected_columns]\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "selected_data.to_csv(\"/rdkit/selected_features.csv\", index=False)\n",
    "\n",
    "print(\"Selected data saved to 'selected_features.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a09da-5dd7-4445-a098-84ca5522ddde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
